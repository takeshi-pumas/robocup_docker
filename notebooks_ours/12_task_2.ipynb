{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "必要なライブラリをインポートして、初期化を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Import the required libraries and initialize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ros_numpy\n",
    "import rospy\n",
    "import tf\n",
    "from gazebo_ros import gazebo_interface\n",
    "from sensor_msgs.msg import LaserScan, PointCloud2\n",
    "from geometry_msgs.msg import Pose, Quaternion ,TransformStamped,PoseStamped\n",
    "import tf2_ros\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "%%script bash --bg\n",
    "\n",
    "rviz -d data/task1.rviz > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cents_to_sceneobjs(cents):\n",
    "    for  i ,cent  in enumerate(cents):\n",
    "        x,y,z=cent\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            print('nan','error')\n",
    "            return False\n",
    "        else:\n",
    "            broadcaster.sendTransform((x,y,z),rot, rospy.Time.now(), 'Closest_Object'+str(i),\"head_rgbd_sensor_link\")\n",
    "            rospy.sleep(.2)\n",
    "            xyz_map,cent_quat= listener.lookupTransform('/map', 'Closest_Object'+str(i),rospy.Time(0))\n",
    "            map_euler=tf.transformations.euler_from_quaternion(cent_quat)\n",
    "            rospy.sleep(.2)\n",
    "\n",
    "\n",
    "            p = PoseStamped()\n",
    "            p.header.frame_id = \"map\"       # \"head_rgbd_sensor_link\"\n",
    "            p.pose.position.x = xyz_map[0]\n",
    "            p.pose.position.y = xyz_map[1]\n",
    "            p.pose.position.z = xyz_map[2]\n",
    "            p.pose.orientation.x = 0.5 * np.pi\n",
    "            p.pose.orientation.w = 0.5 * np.pi\n",
    "            scene.add_box('obs'+str(i),p,(.05,.05,.05) )\n",
    "    return True\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNOWN LOCATIONS\n",
    "kl_mess1= [1.04,0.3,90]\n",
    "kl_table1= [1.04,1.3,90]\n",
    "kl_tray=  [ -0.04168256822546347, 1.5,-90]\n",
    "kl_box1=  [-0.04168256822546347, 2.427268271720426, -90]\n",
    "kl_drawers=  [0.06, 0.038, -90]\n",
    "### ARM \n",
    "arm_grasp_from_above=[0.19263830140116414,\n",
    " -2.2668981568652917,\n",
    " -0.007358947463759424,\n",
    " -0.9939144210462025,\n",
    " -0.17365421548386273,\n",
    " 0.0]\n",
    "arm_grasp_from_above_table=[0.41349380130577407,\n",
    " -1.671584191489468,\n",
    " -0.02774372779356371,\n",
    " -1.5952436225825641,\n",
    " 0.22362492457833927,\n",
    " 0.0]\n",
    "\n",
    "\n",
    "arm_grasp_table=[0.41349380130577407,\n",
    " -1.671584191489468,\n",
    " -0.02774372779356371,\n",
    " 0.0,\n",
    " 0.22362492457833927,\n",
    " 0.0]\n",
    "\n",
    "\n",
    "arm_grasp_floor=[-1.5151551103007697e-05,\n",
    " -2.4,\n",
    " -0.2620865401925543,\n",
    " 0.7019536624449207,\n",
    " 0.20120924571306453,\n",
    " 0.0]\n",
    "arm_train_pose=[0.033749214744071214,\n",
    " -2.1204421063180217,\n",
    " -1.3982377978814715,\n",
    " -1.7296544561013807,\n",
    " 2.135675364707808,\n",
    " 0.0]\n",
    "\n",
    "arm_ready_to_place=[0.03999320441056991,\n",
    " -0.4729690540086997,\n",
    " 0.19361475012179108,\n",
    " -1.5269847787383313,\n",
    " -0.009753879176134461,\n",
    " 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_shelf(): \n",
    "    image= rgbd.get_h_image()\n",
    "    points_data= rgbd.get_points()\n",
    "    values=image.reshape((-1,3))\n",
    "    values= np.float32(values)\n",
    "    criteria= (  cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER  ,1000,0.1)\n",
    "    k=6\n",
    "    _ , labels , cc =cv2.kmeans(values , k ,None,criteria,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    cc=np.uint8(cc)\n",
    "    segmented_image= cc[labels.flatten()]\n",
    "    segmented_image=segmented_image.reshape(image.shape)\n",
    "    th3 = cv2.adaptiveThreshold(segmented_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    im4=cv2.erode(th3,kernel,iterations=4)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=im4\n",
    "    _,contours, hierarchy = cv2.findContours(im4.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > 2000 and area < 20000 :\n",
    "\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            xyz=[]\n",
    "\n",
    "\n",
    "            for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                    xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "            xyz=np.asarray(xyz)\n",
    "            cent=xyz.mean(axis=0)\n",
    "            if np.isnan(cent[0]) or np.isnan(cent[1]) or np.isnan(cent[2]):\n",
    "                'nan in tf....ignoring'\n",
    "            else:\n",
    "                cents.append(cent)\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "            cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "            print ('cX,cY',cX,cY)\n",
    "    cents=np.asarray(cents)\n",
    "    plt.imshow(im4)\n",
    "    \n",
    "    return(cents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_shelf(chan):\n",
    "    image_data=rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "\n",
    "    mask=np.zeros((image_data.shape))\n",
    "    plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "\n",
    "    plane_mask=image_data[:,:,chan]\n",
    "\n",
    "    ret,thresh = cv2.threshold(image_data[:,:,2],200,255,200)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=image_data[:,:,0]\n",
    "    _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > 20 and area < 5000 :\n",
    "            print('contour',i,'area',area)\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            print boundRect\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            xyz=[]\n",
    "\n",
    "\n",
    "            for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                    xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "            xyz=np.asarray(xyz)\n",
    "            cent=xyz.mean(axis=0)\n",
    "            cents.append(cent)\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "            cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "            print ('cX,cY',cX,cY)\n",
    "    cents=np.asarray(cents)\n",
    "    plt.imshow(img )\n",
    "    return (cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_table2(chan):\n",
    "    image_data=rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "\n",
    "    mask=np.zeros((image_data.shape))\n",
    "    plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "\n",
    "    plane_mask=image_data[:,:,chan]\n",
    "\n",
    "    ret,thresh = cv2.threshold(image_data[:,:,2],240,255,200)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=image_data[:,:,0]\n",
    "    _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > 200 and area < 50000 :\n",
    "            print('contour',i,'area',area)\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            print boundRect\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            xyz=[]\n",
    "\n",
    "\n",
    "            for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                    xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "            xyz=np.asarray(xyz)\n",
    "            cent=xyz.mean(axis=0)\n",
    "            cents.append(cent)\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "            cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "            print ('cX,cY',cX,cY)\n",
    "    cents=np.asarray(cents)\n",
    "    plt.imshow(img )\n",
    "    return (cents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def segment_table():\n",
    "    image_data=rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "\n",
    "    mask=np.zeros((image_data.shape))\n",
    "    plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "\n",
    "    plane_mask=image_data[:,:,1]\n",
    "\n",
    "    ret,thresh = cv2.threshold(image_data[:,:,2],240,255,200)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=image_data[:,:,0]\n",
    "    _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > 2000 and area < 50000 :\n",
    "            print('contour',i,'area',area)\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            print boundRect\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            xyz=[]\n",
    "\n",
    "\n",
    "            for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                    xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "            xyz=np.asarray(xyz)\n",
    "            cent=xyz.mean(axis=0)\n",
    "            cents.append(cent)\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "            cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "            print ('cX,cY',cX,cY)\n",
    "    cents=np.asarray(cents)\n",
    "    plt.imshow(img )\n",
    "    return (cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_floor(image,points_data,lower=200,upper=50000):\n",
    "        image_data=rgbd.get_image()\n",
    "        points_data = rgbd.get_points()\n",
    "\n",
    "\n",
    "        ##px pixels /2D world  P1 3D world\n",
    "        px_y,px_x=-1,-200\n",
    "        P1= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        px_y,px_x=-1,200\n",
    "        P2= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        px_y,px_x=-150,320\n",
    "        P3= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        #      \n",
    "\n",
    "        V1 =P1 - P2\n",
    "        V2= P3-P2\n",
    "        nx,ny,nz=np.cross(V2,V1)\n",
    "        print('look at the phi angle  in normal vector', np.rad2deg(cart2spher(nx,ny,nz))[2]-90)\n",
    "        trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "        euler=tf.transformations.euler_from_quaternion(rot)\n",
    "        print(   np.rad2deg(euler)[1],'if this degree is not the same as head tilt plane was not found')\n",
    "        \n",
    "        mask=np.zeros((image_data.shape))\n",
    "        plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "        mask[:,:,0]=points_data['x'] - P1[0]\n",
    "        mask[:,:,1]=points_data['y'] - P1[1]\n",
    "        mask[:,:,2]=points_data['z'] - P1[2]\n",
    "        for i in range (image_data.shape[0]):\n",
    "            for j in range (image_data.shape[1]):\n",
    "                plane_mask[i,j]=-np.dot(np.asarray((nx,ny,nz,)),mask[i,j])\n",
    "        plane_mask=plane_mask-np.min(plane_mask)\n",
    "        plane_mask=plane_mask*256/np.max(plane_mask)\n",
    "        plane_mask.astype('uint8')\n",
    "\n",
    "        ret,thresh = cv2.threshold(plane_mask,3,255,0)\n",
    "\n",
    "        cv2_img=plane_mask.astype('uint8')\n",
    "        img=plane_mask.astype('uint8')\n",
    "        _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        i=0\n",
    "        cents=[]\n",
    "        for i, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if area > lower and area < upper :\n",
    "                #print('contour',i,'area',area)\n",
    "                \n",
    "                boundRect = cv2.boundingRect(contour)\n",
    "                #just for drawing rect, dont waste too much time on this\n",
    "                img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (255,0,0), 2)\n",
    "                # calculate moments for each contour\n",
    "                xyz=[]\n",
    "                \n",
    "                \n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                xyz=np.asarray(xyz)\n",
    "                cent=xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                M = cv2.moments(contour)\n",
    "                # calculate x,y coordinate of center\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        cents=np.asarray(cents)\n",
    "        plt.imshow(img)\n",
    "        return cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_floor():\n",
    "        image_data=rgbd.get_image()\n",
    "        points_data = rgbd.get_points()\n",
    "\n",
    "##### WILL PACKAGE IT BETTER SOON I PROMISE######################################################################\n",
    "        ##px pixels /2D world  P1 3D world\n",
    "        px_y,px_x=-1,-200\n",
    "        P1= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        px_y,px_x=-1,200\n",
    "        P2= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        px_y,px_x=-150,320\n",
    "        P3= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        #      \n",
    "\n",
    "        V1 =P1 - P2\n",
    "        V2= P3-P2\n",
    "        nx,ny,nz=np.cross(V2,V1)\n",
    "        print('look at the phi angle  in normal vector', np.rad2deg(cart2spher(nx,ny,nz))[2]-90)\n",
    "        trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "        euler=tf.transformations.euler_from_quaternion(rot)\n",
    "        print(   np.rad2deg(euler)[1],'if this degree is not the same as head tilt plane was not found')\n",
    "        \n",
    "        mask=np.zeros((image_data.shape))\n",
    "        plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "        mask[:,:,0]=points_data['x'] - P1[0]\n",
    "        mask[:,:,1]=points_data['y'] - P1[1]\n",
    "        mask[:,:,2]=points_data['z'] - P1[2]\n",
    "        for i in range (image_data.shape[0]):\n",
    "            for j in range (image_data.shape[1]):\n",
    "                plane_mask[i,j]=-np.dot(np.asarray((nx,ny,nz,)),mask[i,j])\n",
    "        plane_mask=plane_mask-np.min(plane_mask)\n",
    "        plane_mask=plane_mask*256/np.max(plane_mask)\n",
    "        plane_mask.astype('uint8')\n",
    "\n",
    "        ret,thresh = cv2.threshold(plane_mask,3,255,0)\n",
    "\n",
    "        cv2_img=plane_mask.astype('uint8')\n",
    "        img=plane_mask.astype('uint8')\n",
    "        _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        i=0\n",
    "        cents=[]\n",
    "        for i, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if area > 200 and area < 50000 :\n",
    "                #print('contour',i,'area',area)\n",
    "                \n",
    "                boundRect = cv2.boundingRect(contour)\n",
    "                #just for drawing rect, dont waste too much time on this\n",
    "                img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (255,0,0), 2)\n",
    "                # calculate moments for each contour\n",
    "                xyz=[]\n",
    "                \n",
    "                \n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                xyz=np.asarray(xyz)\n",
    "                cent=xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                M = cv2.moments(contour)\n",
    "                # calculate x,y coordinate of center\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        cents=np.asarray(cents)\n",
    "        plt.imshow(img)\n",
    "        return cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF WRT HEAD SENSOR\n",
    "def static_tf_publish(cents):\n",
    "    for  i ,cent  in enumerate(cents):\n",
    "        x,y,z=cent\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            print('nan')\n",
    "        else:\n",
    "            broadcaster.sendTransform((x,y,z),rot, rospy.Time.now(), 'Closest_Object'+str(i),\"head_rgbd_sensor_link\")\n",
    "            rospy.sleep(.2)\n",
    "            xyz_map,cent_quat= listener.lookupTransform('/map', 'Closest_Object'+str(i),rospy.Time(0))\n",
    "            map_euler=tf.transformations.euler_from_quaternion(cent_quat)\n",
    "            rospy.sleep(.2)\n",
    "            static_transformStamped = TransformStamped()\n",
    "\n",
    "            ##FIXING TF TO MAP ( ODOM REALLY)    \n",
    "            #tf_broadcaster1.sendTransform( (xyz[0],xyz[1],xyz[2]),tf.transformations.quaternion_from_euler(0, 0, 0), rospy.Time.now(), \"obj\"+str(ind), \"head_rgbd_sensor_link\")\n",
    "            static_transformStamped.header.stamp = rospy.Time.now()\n",
    "            static_transformStamped.header.frame_id = \"map\"\n",
    "            static_transformStamped.child_frame_id = \"static\"+str(i)\n",
    "            static_transformStamped.transform.translation.x = float(xyz_map[0])\n",
    "            static_transformStamped.transform.translation.y = float(xyz_map[1])\n",
    "            static_transformStamped.transform.translation.z = float(xyz_map[2])\n",
    "            #quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "            static_transformStamped.transform.rotation.x = 0#-quat[0]#trans.transform.rotation.x\n",
    "            static_transformStamped.transform.rotation.y = 0#-quat[1]#trans.transform.rotation.y\n",
    "            static_transformStamped.transform.rotation.z = 0#-quat[2]#trans.transform.rotation.z\n",
    "            static_transformStamped.transform.rotation.w = 1#-quat[3]#trans.transform.rotation.w\n",
    "\n",
    "\n",
    "            tf_static_broadcaster.sendTransform(static_transformStamped)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2spher(x,y,z):\n",
    "    ro= np.sqrt(x**2+y**2+z**2)\n",
    "    th=np.arctan2(y,x)\n",
    "    phi=np.arctan2((np.sqrt(x**2+y**2)),z)\n",
    "    return np.asarray((ro,th,phi))\n",
    "def spher2cart(ro,th,phi):\n",
    "    x= ro * np.cos(th)* np.sin(phi)\n",
    "    y= ro * np.sin(th)* np.sin(phi)\n",
    "    z= ro*  np.cos(th)\n",
    "    return np.asarray((x,y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rospy.init_node(\"recognition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = tf.TransformListener()\n",
    "broadcaster= tf.TransformBroadcaster()\n",
    "tf_static_broadcaster= tf2_ros.StaticTransformBroadcaster()\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "###might take some time to load all those takeshi meshes in rviz\n",
    "\n",
    "head = moveit_commander.MoveGroupCommander('head')\n",
    "arm = moveit_commander.MoveGroupCommander('arm')\n",
    "whole_body = moveit_commander.MoveGroupCommander('whole_body_light')\n",
    "whole_body.set_workspace([-10.0, -10.0, 10.0, 10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_object(name, size, pose, orientation):\n",
    "    p = PoseStamped()\n",
    "    p.header.frame_id = \"map\"       # \"head_rgbd_sensor_link\"\n",
    "    \n",
    "    p.pose.position.x = pose[0]\n",
    "    p.pose.position.y = pose[1]\n",
    "    p.pose.position.z = pose[2]\n",
    "\n",
    "    p.pose.orientation.x = orientation[0] * np.pi\n",
    "    p.pose.orientation.y = orientation[1] * np.pi\n",
    "    p.pose.orientation.z = orientation[2] * np.pi\n",
    "    p.pose.orientation.w = orientation[3] * np.pi\n",
    "\n",
    "    scene.add_box(name, p, size)\n",
    "\n",
    "\n",
    "def publish_scene():\n",
    "    add_object(\"shelf\", [1.5, 0.04, 0.4],  [2.5, 4.85, 0.78],  [0.5,0,0,0.5])\n",
    "    add_object(\"shelf1\", [1.5, 0.04, 0.4], [2.5, 4.85, 0.49], [0.5,0,0, 0.5])\n",
    "    add_object(\"shelf2\", [1.5, 0.04, 0.4], [2.5, 4.85, 0.18], [0.5,0,0, 0.5])\n",
    "    add_object(\"shelf_wall\", [1, 1, 0.04], [2.5, 4.9, 0.5], [0.5,0,0, 0.5])\n",
    "    add_object(\"shelf_wall1\", [.04, 1, 0.4], [2.7, 4.9, 0.5],[0.5,0,0, 0.5])\n",
    "    add_object(\"shelf_wall2\", [.04, 1, 0.4], [1.8, 4.9, 0.5], [0.5,0,0 ,0.5])    \n",
    "    add_object(\"table_big\", [1.7, 0.13, 0.7], [0.95, 1.9, 0.34],  [0.5,0,0, 0.5])\n",
    "    add_object(\"table_big_legs1\",[.01,.6,.2], [1.55,1.6,0.1],       [0.5,0,0, 0.5])\n",
    "    add_object(\"table_big_legs2\",[.01,.6,.2], [0.45,1.6,0.1],       [0.5,0,0 ,0.5])\n",
    "    add_object(\"table_small\", [0.7, 0.01, 0.4], [0.1, 1.85, 0.61],  [0.5,0,0 ,0.5])\n",
    "    add_object(\"table_small_legs1\",[.01,.6,.2], [-0.2,1.7,0.3],      [0.5,0,0, 0.5])\n",
    "    add_object(\"table_small_legs2\",[.01,.6,.2], [0.18,1.7,0.3], [0.5,0,0 ,0.5])\n",
    "    add_object(\"table_tray\", [0.65, 0.01, 0.7], [1.8, -0.65, 0.4], [0.5,0,0, 0.5])\n",
    "    add_object(\"big_wall\" , [6.0, 0.2, 0.2], [3.2,  2.0, 0.0],  [0,0.0,0.5 ,0.5])\n",
    "    add_object(\"mid_wall\" , [4.0, 0.2, 0.6], [0.1,  2.1, 0.3],  [0,0.0,0.0 ,1/np.pi])##COME ON.....\n",
    "    add_object(\"door_wall\" , [5.0, 0.2, 0.2], [-0.8, 2.8, 0.0],  [0,0.0,0.5 ,0.5     ])\n",
    "    add_object(\"close_wall\", [4.0, 0.2, 0.2], [1.1, -0.5, 0.0],  [0,0.0,0.0 ,1/np.pi])##COME ON.....\n",
    "    add_object(\"far_wall\",   [4.0, 0.2, 0.2], [1.1, 5.0, 0.0],  [0,0.0,0.0 ,1/np.pi])##COME ON.....\n",
    "    \n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "rvizを起動します．ロボットモデル、カメラ映像、ポイントクラウドが表示されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd = RGBD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = moveit_commander.PlanningSceneInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_pub = rospy.Publisher('planning_scene',\n",
    "                                         moveit_msgs.msg.PlanningScene,\n",
    "                                         queue_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_scene()\n",
    "#scene.remove_world_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "from move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\n",
    "from geometry_msgs.msg import PoseStamped, Point , Quaternion\n",
    "from actionlib_msgs.msg import GoalStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "#goal_x , goal_y,goal_yaw= kl_drawers\n",
    "#scene.remove_world_object()\n",
    "#Takeshi neutral\n",
    "move_hand(0)\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()\n",
    "move_base_goal(2.5,1,90)\n",
    "scene.remove_world_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "#wb[3]+=0.6\n",
    "#whole_body.go(wb)\n",
    "head_val=head.get_current_joint_values()\n",
    "head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-45)\n",
    "\n",
    "head.go(head_val)\n",
    "\n",
    "trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "\n",
    "euler=tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "trans, euler\n",
    "\n",
    "#cents=segment_shelf(2)\n",
    "cents=segment_floor()\n",
    "#arm.go(arm_grasp_floor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_scene()\n",
    "#deprecate segmentation_floor in favor of seg_floor()\n",
    "cents=seg_floor(rgbd.get_image(),rgbd.get_points(),2,5000)\n",
    "if len (cents!=0):\n",
    "    static_tf_publish(cents)\n",
    "    cents_to_sceneobjs(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(0)\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()\n",
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]=3.7\n",
    "wb[1]=2.5\n",
    "wb[2]=np.pi\n",
    "#wb[3]+=0.5\n",
    "whole_body.go(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_base_goal(2.3,4,180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_base_goal(goal_x,goal_y,goal_yaw)\n",
    "#move_base_goal(2.2,4.0,goal_yaw)\n",
    "#arm.go(arm_grasp_floor)\n",
    "publish_scene()\n",
    "head_val=head.get_current_joint_values()\n",
    "head_val[0]=np.deg2rad(-90)\n",
    "head_val[1]=np.deg2rad(-30)\n",
    "\n",
    "head.go(head_val)\n",
    "\n",
    "trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "\n",
    "euler=tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "trans, euler\n",
    "cents=seg_shelf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cents=segment_shelf(2)\n",
    "\n",
    "\n",
    "\n",
    "if len (cents!=0):\n",
    "    static_tf_publish(cents)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=0.2\n",
    "whole_body.go(wb)\n",
    "cents=seg_shelf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_tf_publish(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head.set_named_target('neutral')\n",
    "head.go()\n",
    "arm.set_named_target('neutral')\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "nbTranslate": {
   "displayLangs": [
    "ja"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "ja",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
